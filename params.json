{"attention_size": 1024,
  "num_layers": 1,
  "model": "LSTM",
  "hidden_size": 256,
  "n_outputs": 10,
  "filter_sizes": [2, 3, 4, 5, 6, 7, 8],
  "num_filters": 3,
  "pretrain": true,
  "embedding_size": 300,
  "learning_rate": 0.001,
  "keep_ratio": 0.5,
  "epochs": 200,
  "max_char": 23,
  "max_len": 95,
  "train": false
}