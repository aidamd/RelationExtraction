{"attention_size": 512, "num_layers": 1, "model": "LSTM", "hidden_size": 256, "n_outputs": 19, "": 500, "filter_sizes": [2, 3, 4], "num_filters": 3, "attributes": ["sentence"], "pretrain": true, "embedding_size": 300, "learning_rate": 0.0005, "keep_ratio": 0.7, "epochs": 1000, "lemmatize": true, "stop-words": true, "max_char": 23, "max_len": 95}